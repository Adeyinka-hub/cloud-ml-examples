{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving model performance with xfeat, RAPIDS and Optuna\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Feature Engineering is the processing of transforming raw data into features that can represent the underlying patterns of the data better. They can help boost the accuracy by a great deal and improve the ability of the model to generalise on unseen data. Every data scientist knows the importance feature engineering. Spending some time thinking about how best to apply and combine the available features can be very meaningful. \n",
    "\n",
    "Hyper parameter Optimisation is another such process which can help complement a good model by tuning it's hyperparameters, which can have a tremendous impact on the accuracy of the model. The time and resources required for these processes are generally the reason they're overlooked. \n",
    "\n",
    "With xfeat, RAPIDS and Optuna - we aim to bridge these gaps and elevate the performance. \n",
    "\n",
    "## What is Optuna?\n",
    "[Optuna](https://github.com/optuna/optuna) s a lightweight framework for automatic hyperparameter optimization. It provides a define-by-run API, which makes it easy to adapt to any already existing code that we have and enables high modularity and the flexibility to construct hyperparameter spaces dynamically. By simply wrapping the objective function with Optuna can help perform a parallel-distributed HPO search over a search space. As we'll see in this notebook.\n",
    "\n",
    "## What is xfeat?\n",
    "[xfeat](https://github.com/pfnet-research/xfeat) is a feature engineering & exploration library using GPUs and Optuna. It provides a scikit-learn-like API for feature engineering with support for pandas and cuDF dataframes and cuPy arrays. \n",
    "\n",
    "## What is MLflow?\n",
    "[MLflow](https://mlflow.org/https://mlflow.org/) MLflow is an, \"open source platform to manage the ML lifecycle, including experimentation, reproducibility, deployment, and a central model registry\".\n",
    "\n",
    "## What is RAPIDS?\n",
    "[RAPIDS](https://rapids.ai/about.html) framework  provides a library suite that can execute end-to-end data science pipelines entirely on GPUs.  The libraries in the framework include [cuDF](https://github.com/rapidsai/cudf) - a GPU Dataframe with pandas-like API, [cuML](https://github.com/rapidsai/cuml) - implement machine learning algorithms that provide a scikit-learn-like API and many more. You can learn more [here](https://github.com/rapidsai).\n",
    "\n",
    "In this notebook, we'll show how one can use these tools together to develop and improve a machine learning model. We'll use Airlines dataset (20M rows) to predict if a flight will be delayed or not. We'll explore how to use Optuna with RAPIDS and the speedups that we can achieve with the integration of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import requests\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import cupy\n",
    "import cudf\n",
    "import cuml\n",
    "from cuml import LogisticRegression\n",
    "from cuml.metrics import accuracy_score\n",
    "from cuml.preprocessing.model_selection import train_test_split\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from  mlflow.tracking import MlflowClient\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "import optuna\n",
    "from optuna.integration.mlflow import MLflowCallback\n",
    "from optuna.study import StudyDirection\n",
    "from optuna.trial import TrialState\n",
    "from optuna import type_checking\n",
    "\n",
    "import xfeat\n",
    "from xfeat.pipeline import Pipeline\n",
    "from xfeat.num_encoder import SelectNumerical\n",
    "from xfeat.selector import ChiSquareKBest\n",
    "from xfeat.optuna_selector import KBestThresholdExplorer, GroupCombinationExplorer\n",
    "from functools import partial\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "\n",
    "from xfeat import ArithmeticCombinations, Pipeline, SelectNumerical, LabelEncoder, SelectCategorical, TargetEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "We'll be using the following functions to perform a few feature engineering tasks on the data. The `feature_engineering` function is called on the dataframe `df`, in this function we perform a simple Arithmetic Combinations on the numerical columns that adds two columns to create a new one. We specify the `operator` and `r` - r is used to indicate how many columns need to be combined.\n",
    "\n",
    "Then we call `categorical_encoding` which converts the categorical columns to numerical ones and then performs `target_encoding`. Target Encoding replaces the value with the target mean. This is helpful in classification problem to boost the model accuracy. Find more resources at the end of the notebook.\n",
    "\n",
    "You'll also notice we use `Pipeline` from xfeat to combine two or more feature engineering tasks together. This is useful to concatenate encoders sequentially.\n",
    "\n",
    "Read more about Feature Encoding and Pipelining with xfeat [here](https://github.com/pfnet-research/xfeat/blob/master/_docs/feature_encoding.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    \"\"\"\n",
    "    Perform feature engineering and return a new df with engineered features\n",
    "    \"\"\"\n",
    "    df_train, df_test, y_train, y_test = train_test_split(df, \"ArrDelayBinary\", train_size=0.7, random_state=np.random.seed(0), shuffle=True)\n",
    "    \n",
    "    # Xfeat's internal fold mechanism creates RangeIndex references, so we need to do an index reset on our data frames.\n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "    df_test = df_test.reset_index(drop=True)\n",
    "    y_train = y_train.reset_index(drop=True)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "    \n",
    "    # Need to do this to ensure we are appropriately assigning the split values\n",
    "    df_train[\"ArrDelayBinary\"] = y_train\n",
    "    df_test[\"ArrDelayBinary\"] = y_test\n",
    "    \n",
    "    # combine into one pipeline\n",
    "    encoder = Pipeline([\n",
    "                        LabelEncoder(output_suffix=\"\"),\n",
    "                        TargetEncoder(target_col=\"ArrDelayBinary\", output_suffix=\"\"),\n",
    "                        ArithmeticCombinations(exclude_cols=[\"ArrDelayBinary\"],\n",
    "                                               drop_origin=False,\n",
    "                                               operator=\"+\",\n",
    "                                               r=2,\n",
    "                                               output_suffix=\"_plus\")\n",
    "                    ])\n",
    "    df_train = encoder.fit_transform(df_train)\n",
    "    df_test = encoder.transform(df_test)\n",
    "    df = cudf.concat([df_train, df_test], sort=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLflow Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_TRACKING_URI='sqlite:////tmp/mlflow-db.sqlite'\n",
    "MLFLOW_MODEL_ID = \"rapids-optuna-airline\"\n",
    "\n",
    "def get_latest_mlflow_model(tracking_uri, model_id):\n",
    "    client = MlflowClient(tracking_uri=tracking_uri, registry_uri=tracking_uri)\n",
    "    model = client.get_registered_model(model_id)\n",
    "    latest_model = model.latest_versions[0]\n",
    "\n",
    "    return f\"MLFLOW_TRACKING_URI={tracking_uri} mlflow models serve --no-conda -m models:/{model_id}/{latest_model.version} -p 56767\"\n",
    "\n",
    "## Custom callback, for additional flexibility, based on MLflowCallback\n",
    "class RAPIDSMLflowCallback(object):\n",
    "    def __init__(self, tracking_uri: str = \"sqlite:////tmp/mlflow-db.sqlite\",\n",
    "                 experiment_name: str = \"RAPIDS-Optuna\",\n",
    "                 metric_name=\"value\"):\n",
    "        self._tracking_uri = tracking_uri\n",
    "        self._experiment_name = experiment_name\n",
    "        self._metric_name = metric_name\n",
    "        \n",
    "    def __call__(self, study, trial):\n",
    "        if (self._tracking_uri is not None):\n",
    "            mlflow.set_tracking_uri(self._tracking_uri)\n",
    "        \n",
    "        eid = mlflow.set_experiment(self._experiment_name)\n",
    "        with mlflow.start_run(run_name=f\"Trial: {trial.number}\", experiment_id=eid, nested=True):\n",
    "            trial_value = trial.value if trial.value is not None else float(\"nan\")\n",
    "            mlflow.log_metric(self._metric_name, trial_value)\n",
    "            \n",
    "            mlflow.log_params(trial.params)\n",
    "\n",
    "            tags = {}\n",
    "            tags[\"number\"] = str(trial.number)\n",
    "            tags[\"datetime_start\"] = str(trial.datetime_start)\n",
    "            tags[\"datetime_complete\"] = str(trial.datetime_complete)\n",
    "            tags['RAPIDS cuDF Version'] = str(cudf.__version__)\n",
    "            tags['RAPIDS cuML Version'] = str(cuml.__version__)\n",
    "            tags['SKlearn Version'] = str(sklearn.__version__)\n",
    "\n",
    "            trial_state = trial.state\n",
    "            if (isinstance(trial_state, TrialState)):\n",
    "                tags['state'] = str(trial_state).split('.')[-1]\n",
    "            \n",
    "            # Set direction and convert it to str and remove the common prefix.\n",
    "            study_direction = study.direction\n",
    "            if isinstance(study_direction, StudyDirection):\n",
    "                tags[\"direction\"] = str(study_direction).split(\".\")[-1]\n",
    "\n",
    "            tags.update(trial.user_attrs)\n",
    "            distributions = {\n",
    "                (k + \"_distribution\"): str(v) for (k, v) in trial.distributions.items()\n",
    "            }\n",
    "            tags.update(distributions)\n",
    "\n",
    "            # This is a temporary fix on Optuna side. It avoids an error with user\n",
    "            # attributes that are too long. It should be fixed on MLflow side later.\n",
    "            # When it is fixed on MLflow side this codeblock can be removed.\n",
    "            # see https://github.com/optuna/optuna/issues/1340\n",
    "            # see https://github.com/mlflow/mlflow/issues/2931\n",
    "            max_mlflow_tag_length = 5000\n",
    "            for key, value in tags.items():\n",
    "                value = str(value)  # make sure it is a string\n",
    "                if len(value) > max_mlflow_tag_length:\n",
    "                    tags[key] = textwrap.shorten(value, max_mlflow_tag_length)\n",
    "\n",
    "            mlflow.set_tags(tags) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection and Hyper parameter Optimisation\n",
    "\n",
    "Now that we have some new features, how do we know they are relevant for the task or represent anything meaningful? We use the feature selection process to do this. This helps in selection of a subset of features that are  most informative. This helps in simplifying the problem and ensures that we aren't overloading the system with unimportant features. Optuna provides a way to choose a `selector` which accepts a `Pipeline` object from xfeat. You can see in the `feature_selection` function we define a Pipeline that takes in an Explorer and a Selection Algorithm (`ChiSquareKBest`). We pass this to an Optuna Study object, along with an Objective function\n",
    "\n",
    "### Objective Function\n",
    "The objective function will be the one we optimize in Optuna Study. Objective funciton tries out different values for the parameters that we are tuning and saving the results in `study.trials_dataframes()`.\n",
    "\n",
    "Let's define the objective function for this HPO task by making use of the `train_and_eval()`. You can see that we simply choose a value for the parameters and call the `train_and_eval` method, making Optuna very easy to use in an existing workflow.\n",
    "\n",
    "The objective remains constant over different samplers, which are built-in options in Optuna to enable the selection of different sampling algorithms that optuna provides. Some of the available ones include - GridSampler, RandomSampler, TPESampler, etc. We'll use TPESampler for this demo, but feel free to try different samplers to notice the chnages in performance.\n",
    "\n",
    "\n",
    "### HPO Trials and Study\n",
    "Optuna uses [study](https://optuna.readthedocs.io/en/stable/reference/study.html) and [trials](https://optuna.readthedocs.io/en/stable/reference/trial.html) to keep track of the HPO experiments. Put simply, a trial is a single call of the objective function while a set of trials make up a study. We will pick the optimal performing trial from a study to get the best parameters that were used in that run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(df, penalty='l2', C=1.0, l1_ratio='None', fit_intercept='True', selector=None, return_model=False):\n",
    "    # Splitting data and prepping for selector fit\n",
    "    X_train,  X_test, y_train, y_test = train_test_split(df, \"ArrDelayBinary\",random_state=np.random.seed(0), shuffle=True)\n",
    "    # Xfeat's internal fold mechanism creates RangeIndex references, so we need to do an index reset on our data frames.\n",
    "\n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    X_test = X_test.reset_index(drop=True)\n",
    "    y_train = y_train.reset_index(drop=True)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "    \n",
    "    if selector:\n",
    "        # For the selector, the label also needs to be in the DF\n",
    "        X_train[\"ArrDelayBinary\"] = y_train\n",
    "        X_test[\"ArrDelayBinary\"] = y_test\n",
    "        \n",
    "        X_train = selector.fit_transform(X_train)\n",
    "        X_test = selector.transform(X_test)\n",
    "    \n",
    "    # Train and get accuracy\n",
    "    classifier = LogisticRegression(penalty=penalty,\n",
    "                                    C=C,\n",
    "                                    l1_ratio=l1_ratio,\n",
    "                                    fit_intercept=fit_intercept,\n",
    "                                    max_iter=10000)\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict_proba(X_test.values)[:, 1]\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    if (return_model):\n",
    "        return score, classifier, infer_signature(X_test.to_pandas(), cupy.asnumpy(y_pred))\n",
    "    \n",
    "    return score\n",
    "\n",
    "def objective(df, selector, trial):\n",
    "    \"\"\"\n",
    "    Performs the training and evaluation of the set of parameters and subset of features using selector.\n",
    "    \"\"\"\n",
    "    selector.set_trial(trial)\n",
    "    \n",
    "    # Select Params\n",
    "    C = trial.suggest_uniform(\"C\", 0 , 7.0)\n",
    "    penalty = trial.suggest_categorical(\"penalty\", ['l1', 'none', 'l2'])\n",
    "    l1_ratio = trial.suggest_uniform(\"l1_ratio\", 0 , 1.0)\n",
    "    fit_intercept = trial.suggest_categorical(\"fit_intercept\", [True, False])\n",
    "    \n",
    "    score = train_and_eval(df,\n",
    "                           penalty=penalty,\n",
    "                           C=C,\n",
    "                           l1_ratio=l1_ratio,\n",
    "                           fit_intercept=fit_intercept,\n",
    "                           selector=selector)\n",
    "    return score\n",
    "\n",
    "def feature_selection(df, experiment_name):\n",
    "    \"\"\"\n",
    "    Defines the Pipeline and performs the optuna opt\n",
    "    \"\"\"\n",
    "    artifact_path = \"rapids-optuna-airline\"\n",
    "    selector = Pipeline(\n",
    "        [\n",
    "            SelectNumerical(),\n",
    "            KBestThresholdExplorer(ChiSquareKBest(target_col=\"ArrDelayBinary\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    mlfcb = RAPIDSMLflowCallback(\n",
    "        tracking_uri=MLFLOW_TRACKING_URI,\n",
    "        experiment_name=experiment_name,\n",
    "        metric_name='accuracy')\n",
    "    \n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    \n",
    "\n",
    "    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    with mlflow.start_run(run_name=f\"Optuna-HPO:{study.study_name}\"):\n",
    "        study.optimize(partial(objective, df, selector), n_trials=N_TRIALS, callbacks=[mlfcb])\n",
    "        \n",
    "        selector.from_trial(study.best_trial)\n",
    "        selected_cols = selector.get_selected_cols()\n",
    "        df_select = df[selected_cols]\n",
    "        df_select['ArrDelayBinary'] = df['ArrDelayBinary']\n",
    "        \n",
    "        params = study.best_params\n",
    "        score, classifier, signature = train_and_eval(df_select,\n",
    "                      C=params['C'],\n",
    "                      penalty=params['penalty'],\n",
    "                      l1_ratio=params['l1_ratio'],\n",
    "                      fit_intercept=params['fit_intercept'],\n",
    "                      return_model=True)\n",
    "        \n",
    "        with mlflow.start_run(run_name='Final Classifier', nested=True):\n",
    "            mlflow.log_metric('accuracy', score)\n",
    "            mlflow.log_params(params)\n",
    "            mlflow.sklearn.log_model(classifier,\n",
    "                                 signature=signature,\n",
    "                                 artifact_path=artifact_path,\n",
    "                                 registered_model_name=\"rapids-optuna-airline\",\n",
    "                                 conda_env='conda/conda.yaml')\n",
    "\n",
    "    return study, df_select.reset_index(drop=True)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE = \"./airline_data/airline_small.parquet\"\n",
    "\n",
    "N_ROWS = 10000000\n",
    "N_TRIALS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = cudf.read_parquet(INPUT_FILE)[:N_ROWS]\n",
    "\n",
    "df_ = df_.drop([\"ActualElapsedTime\"], axis=1)\n",
    "# Can't handle nagative values, yet\n",
    "# indices = df_.loc[df_[\"ActualElapsedTime\"] < 0].index\n",
    "# df_.loc[indices, \"ActualElapsedTime\"] = -1 * df_.loc[indices, \"ActualElapsedTime\"]\n",
    "\n",
    "# cuML can't handle object types\n",
    "df_[\"ArrDelayBinary\"] = df_[\"ArrDelayBinary\"].astype('int32')\n",
    "print(\"Default performance: \", train_and_eval(df_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We cast to objects for categorical  and target encoding\n",
    "df_[\"UniqueCarrier\"] = df_[\"UniqueCarrier\"].astype(\"object\")\n",
    "df_[\"Origin\"] = df_[\"Origin\"].astype(\"object\")\n",
    "df_[\"Dest\"] = df_[\"Dest\"].astype(\"object\")\n",
    "df_[\"ArrDelayBinary\"] = df_[\"ArrDelayBinary\"].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_eng = feature_engineering(df_)\n",
    "score = train_and_eval(df_feature_eng)\n",
    "print(\"After feature eng: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable Alembic driver, used by MLflow, from logging INFO messages to the command line.\n",
    "logging.getLogger('alembic').setLevel(logging.CRITICAL)\n",
    "study, df_select = feature_selection(df_feature_eng, experiment_name='Optuna Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select[\"ArrDelayBinary\"] = df_[\"ArrDelayBinary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = study.best_params\n",
    "score, classifier, signature = train_and_eval(df_select,\n",
    "                      C=params['C'],\n",
    "                      penalty=params['penalty'],\n",
    "                      l1_ratio=params['l1_ratio'],\n",
    "                      fit_intercept=params['fit_intercept'],\n",
    "                      return_model=True)\n",
    "\n",
    "print(\"After feature selection and paramter tuning: \", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study.trials_dataframe().to_csv(\"xfeat_chi2_100Trials_run3_catenc.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve best model results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|Run No.|Default|After FE| Optuna Best| After Selection and HPO|Best Params| Cols|\n",
    "|-|-|-|-|-|-|-|\n",
    "|1|0.18747319281101227|0.18743759393692017|0.812965989112854|0.8126764297485352| {'C': 2.7250515887031064,'penalty': 'l2','l1_ratio':0.1403560039741595, 'fit_intercept': True, 'KBestThresholdExplorer.k': 1.0} |['UniqueCarrierFlightNum_plus', 'ArrDelayBinary']|\n",
    "|2|0.18741360306739807|0.1874103993177414|0.812959611415863|0.8120356202125549|{'C': 3.398344321379011,'penalty': 'none','l1_ratio': 0.5549805266380305,'fit_intercept': True,'KBestThresholdExplorer.k': 1.0}|['FlightNumDistance_plus', 'ArrDelayBinary']|\n",
    "|3|0.18733720481395721|0.18729199469089508|0.8128544092178345|0.812743604183197|{'C': 4.202429766198819, 'penalty': 'none', 'l1_ratio': 0.6571582748501704, 'fit_intercept': False, 'KBestThresholdExplorer.k': 1.0}|['UniqueCarrierFlightNum_plus', 'ArrDelayBinary']|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch our optimized model within the MLflow framework.\n",
    "Run the code block below to identify the most recently registered model, with the 'rapids-optuna-airline' tag; after identifying the latest model version, run the code below in a separate terminal, and wait for it to fully load your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Run the command below in a terminal, and wait for it to load your model:\\n\\n  \\\n",
    "      {get_latest_mlflow_model(MLFLOW_TRACKING_URI, MLFLOW_MODEL_ID)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see output similar to the following:\n",
    "\n",
    "```shell\n",
    "2020/07/27 13:59:49 INFO mlflow.models.cli: Selected backend for flavor 'python_function'\n",
    "2020/07/27 13:59:49 INFO mlflow.pyfunc.backend: === Running command 'source /anaconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-3335621df6011b1847d2555b195418d4496e5ffd 1>&2 && gunicorn --timeout=60 -b 127.0.0.1:5000 -w 1 ${GUNICORN_CMD_ARGS} -- mlflow.pyfunc.scoring_server.wsgi:app'\n",
    "[2020-07-27 13:59:50 -0600] [23779] [INFO] Starting gunicorn 20.0.4\n",
    "[2020-07-27 13:59:50 -0600] [23779] [INFO] Listening at: http://127.0.0.1:5000 (23779)\n",
    "[2020-07-27 13:59:50 -0600] [23779] [INFO] Using worker: sync\n",
    "[2020-07-27 13:59:50 -0600] [23788] [INFO] Booting worker with pid: 23788\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host='localhost'\n",
    "port='56767'\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"format\": \"pandas-split\"\n",
    "}\n",
    "\n",
    "data = { \n",
    "    \"columns\": [\"Year\", \"Month\", \"DayofMonth\", \"DayofWeek\", \"CRSDepTime\", \"CRSArrTime\", \"UniqueCarrier\",\n",
    "                \"FlightNum\", \"ActualElapsedTime\", \"Origin\", \"Dest\", \"Distance\", \"Diverted\"],\n",
    "    \"data\": [[1987, 10, 1, 4, 1, 556, 0, 190, 247, 202, 162, 1846, 0]]\n",
    "}\n",
    "\n",
    "while (True):\n",
    "    try:\n",
    "        resp = requests.post(url=\"http://%s:%s/invocations\" % (host, port), data=json.dumps(data), headers=headers)\n",
    "        print('Classification: %s' % (\"ON-Time\" if resp.text == \"[0.0]\" else \"LATE\"))\n",
    "        break\n",
    "    except Exception as e:\n",
    "        errmsg = \"Caught exception attempting to call model endpoint: %s\" % e\n",
    "        print(errmsg)\n",
    "        print(\"... Sleeping ...\")\n",
    "        time.sleep(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "[How to Win a DS Kaggle competition](https://www.coursera.org/learn/competitive-data-science)\n",
    "\n",
    "[Target Encoding and Bayesian Target Encoding](https://towardsdatascience.com/target-encoding-and-bayesian-target-encoding-5c6a6c58ae8c)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Xfeat-Optuna",
   "language": "python",
   "name": "xfeatoptuna"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
