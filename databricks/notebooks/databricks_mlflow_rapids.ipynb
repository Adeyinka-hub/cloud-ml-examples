{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import subprocess\n",
    "import sys\n",
    "import threading\n",
    "from queue import Queue, Empty\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "from cuml.metrics.accuracy import accuracy_score as cuml_acc\n",
    "from cuml.preprocessing.model_selection import train_test_split as cuml_split\n",
    "from cuml.ensemble import RandomForestClassifier as cu_RF\n",
    "\n",
    "from sklearn.model_selection import train_test_split as sk_split\n",
    "from sklearn.metrics import accuracy_score as sk_acc\n",
    "from sklearn.ensemble import RandomForestClassifier as sk_RF\n",
    "import pandas as pd\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define environment helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "USER_NAME = \"\"\n",
    "ACCOUNT_ID = \"\"\n",
    "ACCOUNT_TOKEN = \"\"\n",
    "\n",
    "experiment = \"rapids_mlflow\"\n",
    "dbvars = {\n",
    "    \"MLFLOW_EXPERIMENT_NAME\": f\"/Users/{USER_NAME}/{experiment}\",\n",
    "    \"MLFLOW_TRACKING_URI\": f\"databricks\",\n",
    "    \"DATABRICKS_HOST\": f\"https://{ACCOUNT_ID}.cloud.databricks.com\",\n",
    "    \"DATABRICKS_TOKEN\": f\"{ACCOUNT_TOKEN}\"\n",
    "}\n",
    "\n",
    "def set_databricks_env():\n",
    "    for k, v in dbvars.items():\n",
    "        os.environ[k] = v\n",
    "        \n",
    "    mlflow.set_experiment(f\"/Users/{USER_NAME}/{experiment}\")\n",
    "     \n",
    "set_databricks_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a data loading helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fpath, compute_type):\n",
    "    \"\"\"\n",
    "    Simple helper function for loading data to be used by CPU/GPU models.\n",
    "\n",
    "    :param fpath: Path to the data to be ingested\n",
    "    :param compute_type: [CPU|GPU]\n",
    "    :return: DataFrame wrapping the data at [fpath]. Data will be in either a Pandas or RAPIDS (cuDF) DataFrame\n",
    "    \"\"\"\n",
    "    if 'CPU' in compute_type:\n",
    "        try:\n",
    "            import pandas\n",
    "            import pyarrow\n",
    "            from pyarrow import orc\n",
    "        except Exception as error:\n",
    "            print(f'Failed to import pandas and pyarrow: {error}')\n",
    "    elif 'GPU' in compute_type:\n",
    "        try:\n",
    "            import cudf\n",
    "        except Exception as error:\n",
    "            print(f'Failed to import cuDF modules: {error}')\n",
    "\n",
    "    if 'CPU' in compute_type:\n",
    "        df = pd.read_parquet(fpath)\n",
    "    else:\n",
    "        df = cudf.read_parquet(fpath)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define our training routine, and Hyperopt entry points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train(params, fpath, mode='GPU', hyperopt=False):\n",
    "    \"\"\"\n",
    "    :param params: hyperparameters. Its structure is consistent with how search space is defined. See below.\n",
    "    :param fpath: Path or URL for the training data used with the model.\n",
    "    :param mode: Hardware backend to use for training [CPU|GPU]\n",
    "    :param hyperopt: Use hyperopt for hyperparameter search during training.\n",
    "    :return: dict with fields 'loss' (scalar loss) and 'status' (success/failure status of run)\n",
    "    \"\"\"\n",
    "    max_depth, max_features, n_estimators = params\n",
    "    max_depth, max_features, n_estimators = int(max_depth), float(max_features), int(n_estimators)\n",
    "\n",
    "    df = load_data(fpath, compute_type=mode)\n",
    "\n",
    "    X = df.drop([\"ArrDelayBinary\"], axis=1)\n",
    "    y = df[\"ArrDelayBinary\"].astype('int32')\n",
    "\n",
    "    if mode == \"GPU\":\n",
    "        X_train, X_test, y_train, y_test = cuml_split(X, y, test_size=0.2)\n",
    "        mod = cu_RF(max_depth=max_depth, max_features=max_features, n_estimators=n_estimators)\n",
    "        acc_scorer = cuml_acc\n",
    "    elif mode == \"CPU\":\n",
    "        X_train, X_test, y_train, y_test = sk_split(X, y, test_size=0.2)\n",
    "        mod = sk_RF(max_depth=max_depth, max_features=max_features, n_estimators=n_estimators)\n",
    "        acc_scorer = sk_acc\n",
    "    else:\n",
    "        raise RuntimeError(\"Unknown option. Choose between [CPU, GPU], case sensitive.\")\n",
    "\n",
    "    mod.fit(X_train, y_train)\n",
    "    preds = mod.predict(X_test)\n",
    "    acc = acc_scorer(y_test, preds)\n",
    "\n",
    "    mlparams = {\"max_depth\": str(max_depth),\n",
    "                \"max_features\": str(max_features),\n",
    "                \"n_estimators\": str(n_estimators),\n",
    "                \"mode\": str(mode)}\n",
    "    mlflow.log_params(mlparams)\n",
    "\n",
    "    mlmetrics = {\"accuracy\": acc}\n",
    "    mlflow.log_metrics(mlmetrics)\n",
    "\n",
    "    if (not hyperopt):\n",
    "        return mod\n",
    "\n",
    "    return {'loss': acc, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "def train(params, fpath, mode='GPU', hyperopt=False):\n",
    "    \"\"\"\n",
    "    Proxy function used to call _train\n",
    "    :param params: hyperparameters. Its structure is consistent with how search space is defined. See below.\n",
    "    :param fpath: Path or URL for the training data used with the model.\n",
    "    :param mode: Hardware backend to use for training [CPU|GPU]\n",
    "    :param hyperopt: Use hyperopt for hyperparameter search during training.\n",
    "    :return: dict with fields 'loss' (scalar loss) and 'status' (success/failure status of run)\n",
    "    \"\"\"\n",
    "    with mlflow.start_run(nested=True):\n",
    "        return _train(params, fpath, mode, hyperopt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement our MLFlow training loop, and save our best model to the tracking server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_CONDA_DATA = \"\"\n",
    "PATH_TO_AIRLINE_DATA = \"\"\n",
    "\n",
    "algorithm = 'tpe'\n",
    "conda_env = f'https://{PATH_TO_CONDA_DATA}/conda.yaml'\n",
    "fpath     = f'https://{PATH_TO_AIRLINE_DATA}/airline_small.parquet'\n",
    "mode      = 'GPU'\n",
    "\n",
    "search_space = [\n",
    "    hp.uniform('max_depth', 5, 20),\n",
    "    hp.uniform('max_features', 0., 1.0),\n",
    "    hp.uniform('n_estimators', 150, 1000)\n",
    "]\n",
    "\n",
    "trials = Trials()\n",
    "algorithm = tpe.suggest if algorithm == 'tpe' else None\n",
    "fn = partial(train, fpath=fpath, mode=mode, hyperopt=True)\n",
    "experid = 0\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.set_tag(\"mlflow.runName\", \"RAPIDS-Hyperopt-Databricks\")\n",
    "    argmin = fmin(fn=fn,\n",
    "                  space=search_space,\n",
    "                  algo=algorithm,\n",
    "                  max_evals=2,\n",
    "                  trials=trials)\n",
    "\n",
    "    print(\"===========\")\n",
    "    fn = partial(train, fpath=fpath, mode=mode, hyperopt=False)\n",
    "    final_model = fn(tuple(argmin.values()))\n",
    "\n",
    "    conda_data = \"\"\n",
    "    if (conda_env.startswith(\"http\")):\n",
    "        import requests\n",
    "\n",
    "        resp = requests.get(conda_env)\n",
    "        conda_data = str(resp.text)\n",
    "    else:\n",
    "        with open(conda_env, 'r') as reader:\n",
    "            conda_data = reader.read()\n",
    "\n",
    "    with open(\"conda.yaml\", 'w') as writer:\n",
    "        writer.write(conda_data)\n",
    "    \n",
    "    mlflow.sklearn.log_model(final_model,\n",
    "                             artifact_path=\"rapids_mlflow_test\",\n",
    "                             registered_model_name=\"rapids_mlflow_test\",\n",
    "                             conda_env='conda.yaml')\n",
    "\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    latest_model = dict(client.search_model_versions(\"name='rapids_mlflow_test'\")[0])\n",
    "    latest_model_source = latest_model['source']\n",
    "    \n",
    "    retries = 0\n",
    "    while(True):\n",
    "        if (retries > 1):\n",
    "            raise RuntimeError(\"Failed to update registered model status.\")\n",
    "        try:\n",
    "            # We need to wait for the model to be registered\n",
    "            time.sleep(10)\n",
    "            client.transition_model_version_stage(\n",
    "                name=\"rapids_mlflow_test\",\n",
    "                version=latest_model['version'],\n",
    "                stage=\"Production\")\n",
    "            print(f\"Successfully registered model version {latest_model['version']}, as production.\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(e, flush=True)\n",
    "            retries += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper to track our server output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queue_descriptor_output(out, queue):\n",
    "    for line in iter(out.readline, b''):\n",
    "        queue.put(line)\n",
    "    out.close()\n",
    "\n",
    "def follow_subprocess(cmd, timeout=1000, line_timeout=60.00):\n",
    "    p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "    q = Queue()\n",
    "    t = threading.Thread(target=queue_descriptor_output, args=(p.stdout, q))\n",
    "    t.daemon = True\n",
    "    t.start()\n",
    "\n",
    "    elapsed = 0\n",
    "    line_elapsed = 0\n",
    "    last_line_time = time.perf_counter()\n",
    "    while (p.poll() is None and elapsed < timeout and line_elapsed < line_timeout):\n",
    "        try:\n",
    "            time.sleep(2)\n",
    "            elapsed += 2\n",
    "            while (True):\n",
    "                line = q.get(timeout=0.1)\n",
    "                line_elapsed = 0\n",
    "                last_line_time = time.perf_counter()\n",
    "                sys.stdout.write(line.decode())\n",
    "\n",
    "        except Empty:\n",
    "            line_elapsed = (time.perf_counter() - last_line_time)\n",
    "        except KeyboardInterrupt:\n",
    "            sys.stderr.write(\"\\nCaught ctrl+c, killing subprocess ({})\\n\".format(' '.join(cmd)))\n",
    "            p.kill()\n",
    "            raise\n",
    "\n",
    "    try:\n",
    "        p.kill()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    t.join(2)\n",
    "\n",
    "    ## Drain any remaining text\n",
    "    try:\n",
    "        while (True):\n",
    "            line = q.get(timeout=0.1)\n",
    "            sys.stdout.write(line)\n",
    "\n",
    "    except Empty:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin serving our trained model using MLFlow\n",
    "### Note: the serving thread will continue to run in this cell. Select the cell and click 'interrupt the kernel' to stop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port = 55754\n",
    "host = 'localhost'\n",
    "command = f\"mlflow models serve -m {latest_model_source} -p {port} -h {host}\".split()\n",
    "kwargs = { \"cmd\": command, \"timeout\":float('Inf'), \"line_timeout\": float('Inf') }\n",
    "\n",
    "threading.Thread(target=follow_subprocess, kwargs=kwargs).start()\n",
    "\n",
    "## Wait for service to come up.\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make requests against the deployed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"format\": \"pandas-split\"\n",
    "}\n",
    "\n",
    "data = { \n",
    "    \"columns\": [\"Year\", \"Month\", \"DayofMonth\", \"DayofWeek\", \"CRSDepTime\", \"CRSArrTime\", \"UniqueCarrier\", \"FlightNum\", \"ActualElapsedTime\", \"Origin\", \"Dest\", \"Distance\", \"Diverted\"],\n",
    "    \"data\": [[1987, 10, 1, 4, 1, 556, 0, 190, 247, 202, 162, 1846, 0]]\n",
    "}\n",
    "\n",
    "resp = requests.post(url=f\"http://{host}:{port}/invocations\", data=json.dumps(data), headers=headers)\n",
    "print(f'Classification: {\"ON-Time\" if resp.text == \"[0.0]\" else \"LATE\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow",
   "language": "python",
   "name": "mlflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
